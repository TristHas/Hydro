{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b60714f4-6321-46d7-9f08-baa0513d81b2",
   "metadata": {},
   "source": [
    "## This notebook does\n",
    "- Make netCDF file to use neuralhydro's LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "795ee11f-c71b-4378-b24e-f195a4d8562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from dataio import *\n",
    "import pandas as pd\n",
    "import xarray \n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3d6b3ec-a000-400f-a781-c4998c532d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_basin_data(basin: int) -> pd.DataFrame:\n",
    "    \"\"\"Load input and output data from text files.\"\"\"\n",
    "    # get data\n",
    "    idx = int(basin)\n",
    "    rain_msm = load_basin_msm(idx, \"rain\").sum(axis=1).rename('rain_msm').groupby(pd.Grouper(level=0, freq='D')).sum()\n",
    "    rain_gauge = load_rain_gauge(idx).sum(axis=1).rename('rain_gauge').groupby(pd.Grouper(level=0, freq='D')).sum()\n",
    "    rain_gsmsp = load_gsmap(idx, gauge_ajdusted=False).sum(axis=1).rename('rain_gsmap').groupby(pd.Grouper(level=0, freq='D')).sum()\n",
    "    rain_gsmap_gauge = load_gsmap(idx, gauge_ajdusted=True).sum(axis=1).rename('rain_gsmap_gauge').groupby(pd.Grouper(freq='D')).sum()\n",
    "\n",
    "    temp_msm = load_basin_msm(idx, \"temp\").sum(axis=1).rename('temp_msm').groupby(pd.Grouper(level=0, freq='D')).sum()\n",
    "    snmlt_te = load_basin_te(idx,var_name=\"snow_melt\",daily=True).sum(axis=1).rename('snmlt_te')\n",
    "    gsnwl_te = load_basin_te(idx,var_name=\"snow_amount\",daily=True).sum(axis=1).rename('gsnwl_te')\n",
    "\n",
    "    y = pd.concat(load_dam_discharge(idx)).rename('qobs').groupby(pd.Grouper(level=0, freq='D')).mean()\n",
    "    df = pd.concat([rain_msm, rain_gauge, rain_gsmsp, rain_gsmap_gauge, temp_msm, snmlt_te, gsnwl_te, y],axis=1)\n",
    "\n",
    "\n",
    "    start, end = df.index.min(), df.index.max()\n",
    "    df.reindex(pd.date_range(start,end,freq='D'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b0442d-e394-4597-adf9-d996d8756827",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data_details.pkl')\n",
    "idxs = df[~(df['lack of data']) & (df['network exist']) & ~(df['other dams']) & (df['gauge available'])].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce02f5f6-e127-4e3f-aed5-ac61263a9ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for basin in tqdm(idxs):\n",
    "    df = load_basin_data(basin)\n",
    "    df.index.name = 'date'\n",
    "    df.loc[df['qobs'] < 0, 'qobs'] = np.nan\n",
    "\n",
    "    xr = xarray.Dataset.from_dataframe(df)\n",
    "\n",
    "    xr.to_netcdf(f'./CAMELSJP/time_series/{basin}.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
